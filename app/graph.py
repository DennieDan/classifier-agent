import json
import logging
import operator
import time
from typing import Annotated, Dict, List, Literal, TypedDict, Union

from index_query import IndexQuery
from langchain_core.language_models import BaseChatModel
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage
from langgraph.graph import END, START, StateGraph
from prompts.search_prompt import SEARCH_PROMPT
from prompts.supervisor_prompt import SUPERVISOR_PROMPT
from pydantic import BaseModel, Field
from tools.agent_tools import (
    evaluate_search_results,
    get_best_confidence_score_and_compare_with_threshold,
)

# Configure logging (set to logging.WARNING to turn off info logs)
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("graph_log.txt"),
        logging.StreamHandler(),
    ],
)
logger = logging.getLogger(__name__)


# --- 1. Define State ---
class AgentState(TypedDict):
    # The list of messages in the conversation
    messages: Annotated[List[BaseMessage], operator.add]
    # The rules retrieved from the STCCED 2022
    rules: str
    # Supervisor's routing decision
    next_action: str
    # The final answer generated by the worker
    final_answer: str
    # The confidence score assigned by the supervisor
    confidence: float
    # Reasoning for the decision from Supervisor
    supervisor_reasoning: str
    # Instructions for the search agent
    instructions: str
    # Search results from the search agent
    search_results: str
    # Previous search results from the search agent
    previous_search_results: str


# --- 2. Define Structured Output ---
class SupervisorDecision(BaseModel):
    next_action: Literal["search_agent", "FINISH"] = Field(
        description="Select 'search_agent' to find/refine an answer, or 'FINISH' if the answer is satisfactory (>90% confidence)."
    )
    confidence: float = Field(
        description="A score between 0.0 and 1.0 representing confidence. 1.0 = Certain."
    )
    feedback: str = Field(
        description="Reasoning for the decision. If confidence is low, provide specific instructions to search recursively (e.g. 'Check Note 3 of Chapter 85')."
    )
    best_search_result: str = Field(
        description="The best search result from the search agent"
    )


class SearchQuery(BaseModel):
    """Query to run against the index. Use supervisor instructions and user input to form a precise query."""

    query: str = Field(
        description="The search query to run against the classification database (e.g. HS code for a product)."
    )


class SearchAgentDecision(BaseModel):
    search_results: str = Field(
        description="Possible responses from the search agent and reasoning for each possible response"
    )


# --- 3. Define Nodes ---


class AgentGraph:
    def __init__(self, llm: BaseChatModel):
        self.llm = llm
        self.index_query = IndexQuery()
        self.workflow = StateGraph(AgentState)

        # Add Nodes
        self.workflow.add_node("supervisor", self.supervisor_node)
        self.workflow.add_node("search_agent", self.search_agent_node)
        # Add Edges
        # 3. Supervisor -> Decision (Search or Finish)
        self.workflow.add_conditional_edges(
            "supervisor",
            self.route_logic,
            {"search_agent": "search_agent", "FINISH": END, "supervisor": "supervisor"},
        )

        # 4. Search Agent -> Supervisor (Loop back for validation)
        self.workflow.add_edge(START, "supervisor")
        self.workflow.add_edge("search_agent", "supervisor")

        self.app = self.workflow.compile()

    def supervisor_node(self, state: AgentState):
        """
        Supervisor Agent: analyzing input + rules + previous search results.
        """
        messages = state["messages"]
        search_results = state.get("search_results", "")
        evaluation = None

        threshold_met = None
        if search_results:
            evaluation = evaluate_search_results.invoke(
                {
                    "input": messages[0].content,
                    "search_results": search_results,
                }
            )
            if evaluation:
                logger.info(
                    f"\n--- [Supervisor] Search Results Evaluation: {json.dumps(evaluation.evaluation, indent=4)} ---"
                )

        # Build tool descriptions for the prompt
        _supervisor_tools = [
            get_best_confidence_score_and_compare_with_threshold,
        ]
        tools_description = "\n".join(
            f"- **{t.name}**: {t.description}" for t in _supervisor_tools
        )

        # Update System Prompt to include the Retrieved Rules and tool descriptions
        # This is the "Context Injection" pattern
        threshold_line = (
            f"Threshold comparison (best confidence strictly > 0.9): {threshold_met}"
            if threshold_met is not None
            else "N/A (no search results to evaluate)"
        )
        dynamic_system_prompt = f"""
        {SUPERVISOR_PROMPT.format(tools=tools_description)}
        
        === CURRENT SEARCH STATUS ===
        User Input: {messages[0].content}
        Latest Worker Finding: {search_results}
        Search Results Evaluation: {json.dumps(evaluation.evaluation, indent=4) if evaluation else "N/A"}
        {threshold_line}
        """

        structured_llm = self.llm.with_structured_output(SupervisorDecision)
        response = structured_llm.invoke([SystemMessage(content=dynamic_system_prompt)])

        logger.info(
            f"\n--- [Supervisor] Confidence: {response.confidence*100}% | Decision: {response.next_action} ---"
        )
        logger.info(f"\n--- [Supervisor] Feedback/Reasoning: {response.feedback} ---")

        if response.next_action == "FINISH":
            return {
                "next_action": "FINISH",
                "supervisor_reasoning": response.feedback,
                "confidence": response.confidence,
                "final_answer": response.best_search_result,
            }

        return {
            "previous_search_results": search_results,
            "instructions": response.feedback,
            "search_results": "",
            "next_action": response.next_action,
        }

    def search_agent_node(self, state: AgentState):
        """
        Search Agent: Uses index_query as a tool to fetch from the index, then formats the result as SearchAgentDecision.
        """
        messages = state["messages"]
        instructions = state.get("instructions", "")
        previous_search_results = state.get("previous_search_results", "")

        prompt = SEARCH_PROMPT.format(
            user_input=messages[0].content,
            previous_search_results=previous_search_results,
            supervisor_instructions=instructions,
        )

        retrieval_result = self.index_query.index_query(query=prompt)
        logger.info(f"--- [Search Agent] Retrieval Result: {retrieval_result} ---")

        #         prompt_with_results = f"""{prompt}

        # === RETRIEVAL RESULT FROM DATABASE ===
        # {retrieval_result}
        # === END RETRIEVAL RESULT ===

        # Based on the retrieval result above, provide possible responses (e.g. HS-Code and classification details) and reasoning for each."""
        #         structured_llm = self.llm.with_structured_output(SearchAgentDecision)
        #         response = structured_llm.invoke([HumanMessage(content=prompt_with_results)])

        #         logger.info(f"--- [Search Agent] Result: {response}")

        return {
            "search_results": retrieval_result,
            "next_action": "supervisor",
        }

    def route_logic(self, state: AgentState) -> str:
        return state.get("next_action", "search_agent")


# --- 5. Execution ---
# evaluate_search_results is only called from: (1) app/test.py with fixed Virgin Olive Oil,
# (2) this graph's supervisor_node with state["messages"][0].content and state["search_results"].
# So any evaluation output (e.g. electric shavers vs toothbrushes) comes from running this
# graph with that query and search resultsâ€”either by changing content= below or via another script.
