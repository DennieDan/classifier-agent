import json
import logging
import operator
import time
from typing import Annotated, Dict, List, Literal, TypedDict, Union

from constants import get_llm
from index_query import IndexQuery
from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage
from langgraph.graph import END, START, StateGraph
from prompts.evaluate_prompt import EVALUATE_PROMPT
from prompts.search_prompt import SEARCH_PROMPT
from prompts.supervisor_prompt import SUPERVISOR_PROMPT
from pydantic import BaseModel, Field
from tools.agent_tools import evaluate_search_results

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("graph_log.txt"),
        logging.StreamHandler(),
    ],
)
logger = logging.getLogger(__name__)


# --- 1. Define State ---
class AgentState(TypedDict):
    # The list of messages in the conversation
    messages: Annotated[List[BaseMessage], operator.add]
    # The rules retrieved from the STCCED 2022
    rules: str
    # Supervisor's routing decision
    next_action: str
    # The final answer generated by the worker
    final_answer: str
    # The confidence score assigned by the supervisor
    confidence: float
    # Reasoning for the decision from Supervisor
    supervisor_reasoning: str
    # Instructions for the search agent
    instructions: str
    # Search results from the search agent
    search_results: str
    # Previous search results from the search agent
    previous_search_results: str


# --- 2. Define Structured Output ---
class SupervisorDecision(BaseModel):
    next_action: Literal["search_agent", "FINISH"] = Field(
        description="Select 'search_agent' to find/refine an answer, or 'FINISH' if the answer is satisfactory (>90% confidence)."
    )
    confidence: float = Field(
        description="A score between 0.0 and 1.0 representing confidence. 1.0 = Certain."
    )
    feedback: str = Field(
        description="Reasoning for the decision. If confidence is low, provide specific instructions to search recursively (e.g. 'Check Note 3 of Chapter 85')."
    )
    best_search_result: str = Field(
        description="The best search result from the search agent"
    )


class SearchAgentDecision(BaseModel):
    search_results: str = Field(
        description="Possible responses from the search agent and reasoning for each possible response"
    )


llm = get_llm()

# --- 3. Define Nodes ---


class AgentGraph:
    def __init__(self):
        self.llm = get_llm()
        self.index_query = IndexQuery()
        self.workflow = StateGraph(AgentState)

        # Add Nodes
        self.workflow.add_node("supervisor", self.supervisor_node)
        self.workflow.add_node("search_agent", self.search_agent_node)
        # Add Edges
        # 3. Supervisor -> Decision (Search or Finish)
        self.workflow.add_conditional_edges(
            "supervisor",
            self.route_logic,
            {"search_agent": "search_agent", "FINISH": END, "supervisor": "supervisor"},
        )

        # 4. Search Agent -> Supervisor (Loop back for validation)
        self.workflow.add_edge(START, "supervisor")
        self.workflow.add_edge("search_agent", "supervisor")

        self.app = self.workflow.compile()

    def supervisor_node(self, state: AgentState):
        """
        Supervisor Agent: analyzing input + rules + previous search results.
        """
        messages = state["messages"]
        search_results = state.get("search_results", "")
        evaluation = None

        if search_results:
            evaluation = evaluate_search_results.invoke(
                {
                    "input": messages[0].content,
                    "search_results": search_results,
                }
            )
            if evaluation:
                print(
                    f"\n--- [Supervisor] Search Results Evaluation: {json.dumps(evaluation.evaluation, indent=4)} ---"
                )

        # Update System Prompt to include the Retrieved Rules
        # This is the "Context Injection" pattern
        dynamic_system_prompt = f"""
        {SUPERVISOR_PROMPT}
        
        === CURRENT SEARCH STATUS ===
        User Input: {messages[0].content}
        Latest Worker Finding: {search_results}
        Search Results Evaluation: {json.dumps(evaluation.evaluation, indent=4) if evaluation else "N/A"}
        """

        structured_llm = llm.with_structured_output(SupervisorDecision)

        # We invoke with the System Prompt (Context) + User Messages (Task)
        response = structured_llm.invoke([SystemMessage(content=dynamic_system_prompt)])

        logger.info(
            f"\n--- [Supervisor] Confidence: {response.confidence*100}% | Decision: {response.next_action} ---"
        )
        print(f"\n--- [Supervisor] Feedback/Reasoning: {response.feedback} ---")

        if response.next_action == "FINISH":
            return {
                "next_action": "FINISH",
                "supervisor_reasoning": response.feedback,
                "confidence": response.confidence,
                "final_answer": response.best_search_result,
            }

        return {
            "previous_search_results": search_results,
            "instructions": response.feedback,
            "search_results": "",
            "next_action": response.next_action,
        }

    def search_agent_node(self, state: AgentState):
        """
        Search Agent: Fetches specific product details.
        """
        messages = state["messages"]
        instructions = state.get("instructions", "")
        previous_search_results = state.get("previous_search_results", "")

        prompt = SEARCH_PROMPT.format(
            user_input=messages[0].content,
            previous_search_results=previous_search_results,
            supervisor_instructions=instructions,
        )

        structured_llm = llm.with_structured_output(SearchAgentDecision)
        response = structured_llm.invoke(prompt)

        logger.info(
            f"--- [Search Agent] Result: {response.search_results}... ---"
        )  # Log first 100 chars

        return {
            "search_results": response.search_results,
            "next_action": "supervisor",
        }

    def route_logic(self, state: AgentState) -> str:
        return state.get("next_action", "search_agent")


# --- 5. Execution ---
# evaluate_search_results is only called from: (1) app/test.py with fixed Virgin Olive Oil,
# (2) this graph's supervisor_node with state["messages"][0].content and state["search_results"].
# So any evaluation output (e.g. electric shavers vs toothbrushes) comes from running this
# graph with that query and search resultsâ€”either by changing content= below or via another script.
